{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QC_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrJOMY4YuqUDQSjVzSSfJq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1c24f3068ee45178ca552d0b3b003f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_959e4d2c756649579783d629a198b77c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a17f5ac9d0ee40f0a1fb86926fe36ec0",
              "IPY_MODEL_f827dcd6c97c454ba37a58504ece0e99"
            ]
          }
        },
        "959e4d2c756649579783d629a198b77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a17f5ac9d0ee40f0a1fb86926fe36ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49fba45743e84c558add2324281eb186",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74aa1748b52349aba5bcda939d6ade28"
          }
        },
        "f827dcd6c97c454ba37a58504ece0e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cb0e8811b4046c7b1ba0acf51ad5ad5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 3.13MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69c2eb10851b4797b6d7d73989777586"
          }
        },
        "49fba45743e84c558add2324281eb186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74aa1748b52349aba5bcda939d6ade28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cb0e8811b4046c7b1ba0acf51ad5ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69c2eb10851b4797b6d7d73989777586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03f623abdf6b48749addb3d154a88d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc376c481d1a4580aca6cb629b534d62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a3b15011c40472395dc4e4790677e65",
              "IPY_MODEL_94778fee3098423e98c8d1be79885396"
            ]
          }
        },
        "dc376c481d1a4580aca6cb629b534d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a3b15011c40472395dc4e4790677e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae22487cb0064696862a0387bfc333a5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dfda81bae904c5a84ebf353bb21be45"
          }
        },
        "94778fee3098423e98c8d1be79885396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c925600c4bd24cd39c54f57787603e6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.36kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22a398e388464891a2444d1f888459e1"
          }
        },
        "ae22487cb0064696862a0387bfc333a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dfda81bae904c5a84ebf353bb21be45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c925600c4bd24cd39c54f57787603e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22a398e388464891a2444d1f888459e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7b79152b34e4feb98b276d4de0f0d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e22c444e17a9492891791abf8c014b6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae916776a5f6447db2793dba6dff40d5",
              "IPY_MODEL_632af5862ac74938bc16ebab9d786739"
            ]
          }
        },
        "e22c444e17a9492891791abf8c014b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae916776a5f6447db2793dba6dff40d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea309f5dc7fe4366938b9fdac8e14b6b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f946c8241d5747a19bcf26747f4874cc"
          }
        },
        "632af5862ac74938bc16ebab9d786739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11e5badb58e24f31814d556d769b8657",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:05&lt;00:00, 76.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f7560997b29400c9bd85107aeceb785"
          }
        },
        "ea309f5dc7fe4366938b9fdac8e14b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f946c8241d5747a19bcf26747f4874cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11e5badb58e24f31814d556d769b8657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f7560997b29400c9bd85107aeceb785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qd9JpWyPVpy",
        "outputId": "3e88542f-13ea-4f4f-cb8a-8158ea942177"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YRbR_ekPd69"
      },
      "source": [
        "data_path = \"/content/gdrive/My Drive/Data/\"\n",
        "model_path = \"/content/gdrive/My Drive/Models/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__l3TvSoPnGE",
        "outputId": "d42d8f5b-2ecc-4835-edf9-714b590e34c7"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 12.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c909e3d7c4eecb91f7762cba08b765d766dc700610ee0d99091c992231add31f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5kWWbBzQb61"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MATrntszJ8bD"
      },
      "source": [
        "RANDOM_SEED = 0\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTkNv-AiQohs"
      },
      "source": [
        "train_file = open(data_path + 'QC_train.txt')\n",
        "test_file = open(data_path + 'QC_test.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRS1FvLJS0pu"
      },
      "source": [
        "def get_df(inp_file):\n",
        "  return pd.DataFrame(inp_file.readlines(), columns=['Question'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65-xvQwHQ9vV"
      },
      "source": [
        "train_data = get_df(train_file)\n",
        "test_data = get_df(test_file)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "pR7_F-pIRPiE",
        "outputId": "aebd0727-2b10-4ee5-e2e5-c0a8c63123cb"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DESC:manner How did serfdom develop in and the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTY:cremat What films featured the character ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DESC:manner How can I find a list of celebriti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTY:animal What fowl grabs the spotlight afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBR:exp What is the full form of .com ?\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question\n",
              "0  DESC:manner How did serfdom develop in and the...\n",
              "1  ENTY:cremat What films featured the character ...\n",
              "2  DESC:manner How can I find a list of celebriti...\n",
              "3  ENTY:animal What fowl grabs the spotlight afte...\n",
              "4         ABBR:exp What is the full form of .com ?\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Kexlq1SqE7"
      },
      "source": [
        "def improve_df(df):\n",
        "  df['Type'] = df['Question'].apply(lambda s: s.split(' ', 1)[0])\n",
        "  df['Question'] = df['Question'].apply(lambda s: s.split(' ', 1)[1])\n",
        "  df['TypeSimple'] = df['Type'].apply(lambda s: s.split(':')[0])\n",
        "  df['TypeExtended'] = df['Type'].apply(lambda s: s.split(':')[1])\n",
        "  return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_053WWURSJl"
      },
      "source": [
        "train_data = improve_df(train_data)\n",
        "test_data = improve_df(test_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "eA3Txee1TQ3u",
        "outputId": "202d01c2-c7c4-44e2-b309-939ba69060f5"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>DESC:manner</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle...</td>\n",
              "      <td>ENTY:cremat</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>cremat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>DESC:manner</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>ENTY:animal</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>animal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?\\n</td>\n",
              "      <td>ABBR:exp</td>\n",
              "      <td>ABBR</td>\n",
              "      <td>exp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ... TypeExtended\n",
              "0  How did serfdom develop in and then leave Russ...  ...       manner\n",
              "1  What films featured the character Popeye Doyle...  ...       cremat\n",
              "2  How can I find a list of celebrities ' real na...  ...       manner\n",
              "3  What fowl grabs the spotlight after the Chines...  ...       animal\n",
              "4                  What is the full form of .com ?\\n  ...          exp\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Os0yct15Tfwg",
        "outputId": "8ad3c584-c2e4-4fa2-fd9e-279ab756b874"
      },
      "source": [
        "test_data.describe()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>500</td>\n",
              "      <td>42</td>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>What is the speed of light ?\\n</td>\n",
              "      <td>DESC:def</td>\n",
              "      <td>DESC</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>138</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Question      Type TypeSimple TypeExtended\n",
              "count                              500       500        500          500\n",
              "unique                             500        42          6           39\n",
              "top     What is the speed of light ?\\n  DESC:def       DESC          def\n",
              "freq                                 1       123        138          123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "BWxrGtqbUEOR",
        "outputId": "699884b6-1dc9-45b3-b08c-f869a00f1426"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How far is it from Denver to Aspen ?\\n</td>\n",
              "      <td>NUM:dist</td>\n",
              "      <td>NUM</td>\n",
              "      <td>dist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What county is Modesto , California in ?\\n</td>\n",
              "      <td>LOC:city</td>\n",
              "      <td>LOC</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who was Galileo ?\\n</td>\n",
              "      <td>HUM:desc</td>\n",
              "      <td>HUM</td>\n",
              "      <td>desc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is an atom ?\\n</td>\n",
              "      <td>DESC:def</td>\n",
              "      <td>DESC</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When did Hawaii become a state ?\\n</td>\n",
              "      <td>NUM:date</td>\n",
              "      <td>NUM</td>\n",
              "      <td>date</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Question      Type TypeSimple TypeExtended\n",
              "0      How far is it from Denver to Aspen ?\\n  NUM:dist        NUM         dist\n",
              "1  What county is Modesto , California in ?\\n  LOC:city        LOC         city\n",
              "2                         Who was Galileo ?\\n  HUM:desc        HUM         desc\n",
              "3                         What is an atom ?\\n  DESC:def       DESC          def\n",
              "4          When did Hawaii become a state ?\\n  NUM:date        NUM         date"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "UyZFe8cLUHfz",
        "outputId": "ad660fcd-48a6-4ebf-cb25-de98c4ad8c8a"
      },
      "source": [
        "train_data.append(test_data).describe()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5952</td>\n",
              "      <td>5952</td>\n",
              "      <td>5952</td>\n",
              "      <td>5952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5871</td>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>What seven digits follow the area code in the ...</td>\n",
              "      <td>HUM:ind</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>1017</td>\n",
              "      <td>1344</td>\n",
              "      <td>1017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Question  ... TypeExtended\n",
              "count                                                5952  ...         5952\n",
              "unique                                               5871  ...           47\n",
              "top     What seven digits follow the area code in the ...  ...          ind\n",
              "freq                                                    3  ...         1017\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWEYJ9x7dI9h",
        "outputId": "0626d6b3-f16a-44a2-be52-45f13129bdca"
      },
      "source": [
        "train_data['TypeSimple'].unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['DESC', 'ENTY', 'ABBR', 'HUM', 'NUM', 'LOC'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpkwlXDyetap",
        "outputId": "81509c47-561e-461f-92c1-423e4084204a"
      },
      "source": [
        "train_data['TypeExtended'].unique()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['manner', 'cremat', 'animal', 'exp', 'ind', 'gr', 'title', 'def',\n",
              "       'date', 'reason', 'event', 'state', 'desc', 'count', 'other',\n",
              "       'letter', 'religion', 'food', 'country', 'color', 'termeq', 'city',\n",
              "       'body', 'dismed', 'mount', 'money', 'product', 'period',\n",
              "       'substance', 'sport', 'plant', 'techmeth', 'volsize', 'instru',\n",
              "       'abb', 'speed', 'word', 'lang', 'perc', 'code', 'dist', 'temp',\n",
              "       'symbol', 'ord', 'veh', 'weight', 'currency'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upjkwZttdQhe",
        "outputId": "47320071-9eb4-48f6-8ec0-3ff72e231b72"
      },
      "source": [
        "train_data['Type'].unique()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['DESC:manner', 'ENTY:cremat', 'ENTY:animal', 'ABBR:exp', 'HUM:ind',\n",
              "       'HUM:gr', 'HUM:title', 'DESC:def', 'NUM:date', 'DESC:reason',\n",
              "       'ENTY:event', 'LOC:state', 'DESC:desc', 'NUM:count', 'ENTY:other',\n",
              "       'ENTY:letter', 'LOC:other', 'ENTY:religion', 'ENTY:food',\n",
              "       'LOC:country', 'ENTY:color', 'ENTY:termeq', 'LOC:city',\n",
              "       'ENTY:body', 'ENTY:dismed', 'LOC:mount', 'NUM:money',\n",
              "       'ENTY:product', 'NUM:period', 'ENTY:substance', 'ENTY:sport',\n",
              "       'ENTY:plant', 'ENTY:techmeth', 'NUM:volsize', 'HUM:desc',\n",
              "       'ENTY:instru', 'ABBR:abb', 'NUM:other', 'NUM:speed', 'ENTY:word',\n",
              "       'ENTY:lang', 'NUM:perc', 'NUM:code', 'NUM:dist', 'NUM:temp',\n",
              "       'ENTY:symbol', 'NUM:ord', 'ENTY:veh', 'NUM:weight',\n",
              "       'ENTY:currency'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM3TM0O5YJ4D"
      },
      "source": [
        "TARGET_NAMES = train_data['TypeSimple'].unique().tolist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG8pBB8jUSGP"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC0kxtXQIH2N"
      },
      "source": [
        "def encode_tag(train_data, test_data, tag):\n",
        "  l_enc = LabelEncoder()\n",
        "  l_enc.fit(pd.Series(train_data[tag].tolist() + test_data[tag].tolist()).values)\n",
        "  return l_enc.transform(train_data[tag].values), l_enc.transform(test_data[tag].values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy7BJ_gGJGnE"
      },
      "source": [
        "tag = 'Type'\n",
        "train_data[tag], test_data[tag] = encode_tag(train_data, test_data, tag)\n",
        "tag = 'TypeSimple'\n",
        "train_data[tag], test_data[tag] = encode_tag(train_data, test_data, tag)\n",
        "tag = 'TypeExtended'\n",
        "train_data[tag], test_data[tag] = encode_tag(train_data, test_data, tag)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "mwcviZ-rJUhd",
        "outputId": "553d5c5c-b665-44c5-e0ed-38bca2049233"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?\\n</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ...  TypeExtended\n",
              "0  How did serfdom develop in and then leave Russ...  ...            23\n",
              "1  What films featured the character Popeye Doyle...  ...             8\n",
              "2  How can I find a list of celebrities ' real na...  ...            23\n",
              "3  What fowl grabs the spotlight after the Chines...  ...             1\n",
              "4                  What is the full form of .com ?\\n  ...            16\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNmdlghsJXyD",
        "outputId": "3a8dcaa2-b549-4d8a-fa4d-a5fedef4b18c"
      },
      "source": [
        "train_data.columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Question', 'Type', 'TypeSimple', 'TypeExtended'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu8Zh4SVJaUQ",
        "outputId": "8b88586a-6bcc-492c-e3a6-69d0f0454472"
      },
      "source": [
        "train_data['TypeSimple'].unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0, 3, 5, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJdJtM7MJeEP"
      },
      "source": [
        "SRC_COL = 'Question'\n",
        "TRG_COL = 'TypeSimple'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0fNT9MEJvTc",
        "outputId": "0a4b7054-ec73-473a-978e-a6cc1be42aa3"
      },
      "source": [
        "TARGETS = train_data[TRG_COL].unique().tolist()\n",
        "print(TARGETS)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 0, 3, 5, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g82cobeQOk9Z"
      },
      "source": [
        "TARGET_DICT = dict()\r\n",
        "for i in range(len(TARGET_NAMES)):\r\n",
        "  TARGET_DICT[TARGETS[i]] = TARGET_NAMES[i]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkyqEkajO8xZ",
        "outputId": "09ca4fdc-5c71-47f0-82bf-bd7c183f8e50"
      },
      "source": [
        "TARGET_DICT"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ABBR', 1: 'DESC', 2: 'ENTY', 3: 'HUM', 4: 'LOC', 5: 'NUM'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-akN7_t-JymN"
      },
      "source": [
        "BERT_MODEL_NAME = 'bert-base-cased' "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a1c24f3068ee45178ca552d0b3b003f2",
            "959e4d2c756649579783d629a198b77c",
            "a17f5ac9d0ee40f0a1fb86926fe36ec0",
            "f827dcd6c97c454ba37a58504ece0e99",
            "49fba45743e84c558add2324281eb186",
            "74aa1748b52349aba5bcda939d6ade28",
            "2cb0e8811b4046c7b1ba0acf51ad5ad5",
            "69c2eb10851b4797b6d7d73989777586"
          ]
        },
        "id": "-JhfuHcCKCzy",
        "outputId": "2664a397-acd5-4a14-a331-e6e7d56d87b3"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1c24f3068ee45178ca552d0b3b003f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48njcQq_KEmD",
        "outputId": "cd712477-1038-45c3-ef7c-545409462f82"
      },
      "source": [
        "token_lengths = []\n",
        "for sent in train_data[SRC_COL]:\n",
        "  tokens = tokenizer.encode(sent, max_length=tokenizer.max_model_input_sizes[BERT_MODEL_NAME])\n",
        "  token_lengths.append(len(tokens))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEJ_47IgKtcf"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgXKNAm2LBIT"
      },
      "source": [
        "rcParams['figure.figsize'] = 8, 6"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "1ZelRv7BKkV4",
        "outputId": "a899f23c-4d47-4140-a585-4c426494e36a"
      },
      "source": [
        "sns.distplot(token_lengths)\n",
        "plt.xlim([0, tokenizer.max_model_input_sizes[BERT_MODEL_NAME] // 10])\n",
        "plt.xlabel('Token count')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Token count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1hmW44LK3u"
      },
      "source": [
        "MAX_LEN = 32"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qLbePSnLOH2"
      },
      "source": [
        "class QuestionsDataset(Dataset):\n",
        "  def __init__(self, src_list, trg_list, tokenizer, MAX_LEN):\n",
        "    self.src_list = src_list\n",
        "    self.trg_list = trg_list\n",
        "    self.tokenizer = tokenizer\n",
        "    self.MAX_LEN = MAX_LEN\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.src_list)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    src = str(self.src_list[item])\n",
        "    trg = self.trg_list[item]\n",
        "    encoder = tokenizer.encode_plus(\n",
        "      src, add_special_tokens=True,\n",
        "      max_length=self.MAX_LEN,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    return {'src': src, 'input_ids': encoder['input_ids'].flatten(), 'attention_mask': encoder['attention_mask'].flatten(), 'trg': torch.tensor(trg, dtype=torch.long)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uI6JqfTMDdr"
      },
      "source": [
        "def get_loader(df, tokenizer, MAX_LEN, BATCH_SIZE):\n",
        "  data = QuestionsDataset(src_list=df[SRC_COL].to_numpy(), trg_list=df[TRG_COL].to_numpy(), tokenizer=tokenizer, MAX_LEN=MAX_LEN)\n",
        "  loader = DataLoader(data, batch_size=BATCH_SIZE)\n",
        "  return loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_n7keQHMcDd"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = get_loader(train_data, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_loader = get_loader(test_data, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bztMwHUbM4RY",
        "outputId": "da17335a-6578-4cad-c90c-e8f77016718d"
      },
      "source": [
        "data = next(iter(train_loader))\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['trg'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 32])\n",
            "torch.Size([32, 32])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPVO2wH_NBeH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "03f623abdf6b48749addb3d154a88d94",
            "dc376c481d1a4580aca6cb629b534d62",
            "3a3b15011c40472395dc4e4790677e65",
            "94778fee3098423e98c8d1be79885396",
            "ae22487cb0064696862a0387bfc333a5",
            "3dfda81bae904c5a84ebf353bb21be45",
            "c925600c4bd24cd39c54f57787603e6e",
            "22a398e388464891a2444d1f888459e1",
            "a7b79152b34e4feb98b276d4de0f0d35",
            "e22c444e17a9492891791abf8c014b6f",
            "ae916776a5f6447db2793dba6dff40d5",
            "632af5862ac74938bc16ebab9d786739",
            "ea309f5dc7fe4366938b9fdac8e14b6b",
            "f946c8241d5747a19bcf26747f4874cc",
            "11e5badb58e24f31814d556d769b8657",
            "0f7560997b29400c9bd85107aeceb785"
          ]
        },
        "outputId": "a1abddc3-633a-45ee-804d-977bb39fad43"
      },
      "source": [
        "bert = BertModel.from_pretrained(BERT_MODEL_NAME)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03f623abdf6b48749addb3d154a88d94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7b79152b34e4feb98b276d4de0f0d35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuDbZa1WNE4G"
      },
      "source": [
        "res = bert(input_ids=data['input_ids'], attention_mask=data['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IklwYiPuQoYi",
        "outputId": "f87551a3-96ee-40e8-c603-6d91779573a1"
      },
      "source": [
        "res[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C_jKY79R8Lf",
        "outputId": "7b890ccc-236c-4b58-bb32-73937406c8fb"
      },
      "source": [
        "res[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPlN5joj-BGF"
      },
      "source": [
        "res1 = nn.Linear(bert.config.hidden_size, 256 * 2)(res[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urTMImnb-Pel",
        "outputId": "aeb9361a-475a-4892-c9ce-98b85bd12ea8"
      },
      "source": [
        "res1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc6Iut6f_3nw",
        "outputId": "f123dcd6-5eb3-4f07-9a34-9727174e5466"
      },
      "source": [
        "torch.cat((res1, res1), dim=1).reshape(4, res1.size(0), res1.size(1) // 2).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNC1MV3V9bzs"
      },
      "source": [
        "h, hid = nn.GRU(bert.config.hidden_size, 256, num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)(res[0], torch.cat((res1, res1), dim=1).reshape(4, 32, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVbFEY7k9sd0",
        "outputId": "87135e15-15b4-455b-ae95-7ba732b5ef36"
      },
      "source": [
        "h.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKMgMIO29vwo",
        "outputId": "42d6121e-6e7b-4d46-fb1e-b7fb0455d5b1"
      },
      "source": [
        "hid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8KrQn7X93An",
        "outputId": "b9bba597-3fdb-44f2-8d6c-4ac2de5be8b5"
      },
      "source": [
        "torch.cat((hid[-2,:,:], hid[-1,:,:]), dim=1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTccT3pLSdcH"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2out = nn.Linear(self.inp2emb.config.hidden_size, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
        "    emb = self.drop(emb)\n",
        "    out = self.emb2out(emb)\n",
        "    return out"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkIl8Jy5cgir"
      },
      "source": [
        "classifier = Classifier(bert, 0.3, len(TARGETS))\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBWtBSc_df2j"
      },
      "source": [
        "EPOCHS = 5\n",
        "optim = AdamW(classifier.parameters(), lr=2e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNcx5qv7jWq_"
      },
      "source": [
        "class ClassifierV2(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags):\n",
        "    super(ClassifierV2, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2hid = nn.Linear(self.inp2emb.config.hidden_size, self.inp2emb.config.hidden_size)\n",
        "    self.hid2out = nn.Linear(self.inp2emb.config.hidden_size, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
        "    emb = self.drop(emb)\n",
        "    hid = self.emb2hid(emb)\n",
        "    out = self.hid2out(hid)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0I8IABnjbCI"
      },
      "source": [
        "classifierV2 = ClassifierV2(bert, 0.3, len(TARGETS))\n",
        "classifierV2 = classifierV2.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYAUbw78jeTs"
      },
      "source": [
        "EPOCHS = 5\n",
        "optim = AdamW(classifierV2.parameters(), lr=2e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFq8ghoelWFU"
      },
      "source": [
        "class ClassifierV3(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags, hid_dim, num_lay):\n",
        "    super(ClassifierV3, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2hid = nn.GRU(self.inp2emb.config.hidden_size, hid_dim, num_layers=num_lay, bidirectional=True, batch_first=True, dropout=p)\n",
        "    self.hid2out = nn.Linear(hid_dim * 2, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    with torch.no_grad():\n",
        "      emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "    h, hid = self.emb2hid(emb)\n",
        "    hid = self.drop(torch.cat((hid[-2,:,:], hid[-1,:,:]), dim=1))\n",
        "    out = self.hid2out(hid)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slxXaim9oIKK"
      },
      "source": [
        "classifierV3 = ClassifierV3(bert, 0.3, len(TARGETS), 256, 2)\n",
        "classifierV3 = classifierV3.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOSC7mcgcd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf25b523-2906-4617-b45d-2a13c02e9d8f"
      },
      "source": [
        "sum(p.numel() for p in classifierV3.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111072006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBbEY_EBgugW"
      },
      "source": [
        "for name, param in classifierV3.named_parameters():\n",
        "  if name.startswith('inp2emb'):\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Lm6reChKFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086ec7a1-c804-4fc6-8714-cbf92868205f"
      },
      "source": [
        "sum(p.numel() for p in classifierV3.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2761734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KePPOMPoPrC"
      },
      "source": [
        "EPOCHS = 20\n",
        "optim = AdamW(classifierV3.parameters(), lr=5e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKi48BE3mMCI"
      },
      "source": [
        "class ClassifierV4(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags, hid_dim, num_lay):\n",
        "    super(ClassifierV4, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2hid0 = nn.Linear(self.inp2emb.config.hidden_size, hid_dim * 2)\n",
        "    self.emb2hid = nn.GRU(self.inp2emb.config.hidden_size, hid_dim, num_layers=num_lay, bidirectional=True, batch_first=True, dropout=p)\n",
        "    self.hid2out = nn.Linear(hid_dim * 2, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    hid0 = self.emb2hid0(emb[1])\n",
        "    hid0 = torch.cat((hid0, hid0), dim=1).reshape(4, hid0.size(0), hid0.size(1) // 2)\n",
        "    h, hid = self.emb2hid(emb[0], hid0)\n",
        "    hid = self.drop(torch.cat((hid[-2,:,:], hid[-1,:,:]), dim=1))\n",
        "    out = self.hid2out(hid)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKUt0Y5SmQr6"
      },
      "source": [
        "classifierV4 = ClassifierV4(bert, 0.3, len(TARGETS), 128, 2)\n",
        "classifierV4 = classifierV4.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__6FqFbHmXC0"
      },
      "source": [
        "EPOCHS = 10\n",
        "optim = AdamW(classifierV4.parameters(), lr=2e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDxYKnsOdtUR"
      },
      "source": [
        "def train_epoch(model, loader, crit, optim, device, num_ex):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct = 0\n",
        "\n",
        "  for data in loader:\n",
        "    input_ids = data['input_ids'].to(device)\n",
        "    attention_mask = data['attention_mask'].to(device)\n",
        "    trg = data['trg'].to(device)\n",
        "\n",
        "    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    _, pred = torch.max(out, dim=1)\n",
        "    loss = crit(out, trg)\n",
        "    correct += torch.sum(pred == trg)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "  \n",
        "  return correct.double() / num_ex, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWw0JMXfiQhE"
      },
      "source": [
        "def eval(model, loader, crit, device, num_ex):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in loader:\n",
        "      input_ids = data['input_ids'].to(device)\n",
        "      attention_mask = data['attention_mask'].to(device)\n",
        "      trg = data['trg'].to(device)\n",
        "\n",
        "      out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      _, pred = torch.max(out, dim=1)\n",
        "      loss = crit(out, trg)\n",
        "      correct += torch.sum(pred == trg)\n",
        "      losses.append(loss.item())\n",
        "  \n",
        "  return correct.double() / num_ex, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nvNRTsek6ox",
        "outputId": "f09c0a2a-42da-4c66-c76a-b0861dc7bf10"
      },
      "source": [
        "name = 'QC_StandardSimple'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifier, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifier, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifier.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.8409565178274411  | Train acc =  tensor(0.7043, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1858578915707767  | Val acc =  tensor(0.9600, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 5\n",
            "----------\n",
            "Train loss =  0.18142185625974197  | Train acc =  tensor(0.9481, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1711366816307418  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 5\n",
            "----------\n",
            "Train loss =  0.0924385528731002  | Train acc =  tensor(0.9754, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2017734306573402  | Val acc =  tensor(0.9660, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 5\n",
            "----------\n",
            "Train loss =  0.04715117942187826  | Train acc =  tensor(0.9890, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.21390219436580082  | Val acc =  tensor(0.9660, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 5\n",
            "----------\n",
            "Train loss =  0.029092863585380564  | Train acc =  tensor(0.9927, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1765850777810556  | Val acc =  tensor(0.9720, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aSVbOC2YCKC",
        "outputId": "4780260c-d253-4b48-f6e5-1cb5d0fd7085"
      },
      "source": [
        "classifier.load_state_dict(torch.load(model_path + 'QC_StandardSimple.pt'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCEquf50ZebD"
      },
      "source": [
        "def classify(model, sent):\r\n",
        "  encoded = tokenizer.encode_plus(sent, max_length=MAX_LEN, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\r\n",
        "  input_ids = encoded['input_ids'].to(device)\r\n",
        "  attention_mask = encoded['attention_mask'].to(device)\r\n",
        "\r\n",
        "  out = model(input_ids, attention_mask)\r\n",
        "  _, pred = torch.max(out, dim=1)\r\n",
        "\r\n",
        "  return TARGET_DICT[pred.item()]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "chSRMJquNpLt",
        "outputId": "c0165bbb-a164-4503-a3e3-3265293062fb"
      },
      "source": [
        "classify(classifier, 'What does NLP stand for ?')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ABBR'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "m8yRTIc5PW6i",
        "outputId": "a2aac467-98af-4e4b-dd82-9af7152c0551"
      },
      "source": [
        "classify(classifier, 'What is the training strategy for recurrent neural networks ?')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ENTY'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "8Q90e_GZVaao",
        "outputId": "0e157126-3e34-456b-fdeb-248c8b554bbe"
      },
      "source": [
        "classify(classifier, 'What is the training strategy for athletes ?')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DESC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "zoav9S5WPcoI",
        "outputId": "f4c752b7-ebd1-4339-8eb7-c0c74dd8d66d"
      },
      "source": [
        "classify(classifier, 'What is the name of this monitor model ?')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ENTY'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "CQpmbWULUjMI",
        "outputId": "0037ab9f-fec5-49bf-e2b2-3e5e11d23b78"
      },
      "source": [
        "classify(classifier, 'What is the name of a company that produces this monitor model ?')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'HUM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "LbPEp1YXPrDx",
        "outputId": "1f5de9c0-7b1e-4e5d-fa7c-024e20a7be12"
      },
      "source": [
        "classify(classifier, 'What is the highest point in the world ?')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'LOC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "4DvHHiBcXZav",
        "outputId": "19f9d5c5-c6ba-4487-c505-3f0dde9e7fc6"
      },
      "source": [
        "classify(classifier, 'What is the distance to the Moon ?')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NUM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "vJXCXmoMXeR-",
        "outputId": "4333c034-7a5e-43a2-c1b4-ddd81d5cffaa"
      },
      "source": [
        "classify(classifier, 'How far is the Moon ?')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NUM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "IN7NOh2WYW_a",
        "outputId": "c9fb8b28-e055-4515-ec8a-b592d9b36ee7"
      },
      "source": [
        "classify(classifier, 'How fast is a sports car ?')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NUM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "T8yzffWsYct1",
        "outputId": "61529e72-5754-4cd0-8f7b-5238895d9a32"
      },
      "source": [
        "classify(classifier, 'How expensive is a sports car ?')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NUM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "kGjLmYdudzcO",
        "outputId": "d4994f92-113c-43e0-c937-b1975443faaf"
      },
      "source": [
        "classify(classifier, 'How to reveal the truth ?')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DESC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBI3aI1AjkGk",
        "outputId": "43ee3e45-86b5-430c-d81f-8dcb1d11f3aa"
      },
      "source": [
        "name = 'QC_V2Simple'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV2, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV2, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV2.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.8775562671018623  | Train acc =  tensor(0.6799, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.19073277479037642  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 5\n",
            "----------\n",
            "Train loss =  0.2133379129703805  | Train acc =  tensor(0.9457, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1407251110067591  | Val acc =  tensor(0.9720, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 5\n",
            "----------\n",
            "Train loss =  0.11074302133379711  | Train acc =  tensor(0.9738, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.15037238411605358  | Val acc =  tensor(0.9680, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 5\n",
            "----------\n",
            "Train loss =  0.05834613110439863  | Train acc =  tensor(0.9855, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.10013237154635135  | Val acc =  tensor(0.9820, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 5\n",
            "----------\n",
            "Train loss =  0.04128163271619018  | Train acc =  tensor(0.9912, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1513870324124582  | Val acc =  tensor(0.9780, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2xg85DE0Yb9",
        "outputId": "a78a1fb8-1388-4381-91b3-78fbd0d9dd89"
      },
      "source": [
        "name = 'QC_V3Simple'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV3, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV3, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV3.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 20\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  1.4316574411782605  | Train acc =  tensor(0.4820, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9508375227451324  | Val acc =  tensor(0.7360, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 20\n",
            "----------\n",
            "Train loss =  0.8086324316716333  | Train acc =  tensor(0.7386, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.4772086329758167  | Val acc =  tensor(0.8480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 20\n",
            "----------\n",
            "Train loss =  0.5573127893676535  | Train acc =  tensor(0.8036, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.3741667279973626  | Val acc =  tensor(0.8860, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 20\n",
            "----------\n",
            "Train loss =  0.46355545172217294  | Train acc =  tensor(0.8375, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.3264863253571093  | Val acc =  tensor(0.9000, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 20\n",
            "----------\n",
            "Train loss =  0.4123199941993457  | Train acc =  tensor(0.8501, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.27644189447164536  | Val acc =  tensor(0.9080, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 20\n",
            "----------\n",
            "Train loss =  0.36551112903837574  | Train acc =  tensor(0.8703, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.27022023731842637  | Val acc =  tensor(0.9160, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 20\n",
            "----------\n",
            "Train loss =  0.330215095340857  | Train acc =  tensor(0.8832, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2381506443489343  | Val acc =  tensor(0.9180, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 20\n",
            "----------\n",
            "Train loss =  0.31115464360741846  | Train acc =  tensor(0.8894, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2180353265721351  | Val acc =  tensor(0.9340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 20\n",
            "----------\n",
            "Train loss =  0.28982547352537075  | Train acc =  tensor(0.8999, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.20744721230585128  | Val acc =  tensor(0.9320, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 20\n",
            "----------\n",
            "Train loss =  0.2690289280437238  | Train acc =  tensor(0.9044, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.21356755343731493  | Val acc =  tensor(0.9340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  11 / 20\n",
            "----------\n",
            "Train loss =  0.25770559469074533  | Train acc =  tensor(0.9101, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.20904739352408797  | Val acc =  tensor(0.9360, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  12 / 20\n",
            "----------\n",
            "Train loss =  0.23927645988718807  | Train acc =  tensor(0.9169, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.19056820147670805  | Val acc =  tensor(0.9380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  13 / 20\n",
            "----------\n",
            "Train loss =  0.22411327728489686  | Train acc =  tensor(0.9208, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.18417446629609913  | Val acc =  tensor(0.9340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  14 / 20\n",
            "----------\n",
            "Train loss =  0.21861148648486847  | Train acc =  tensor(0.9233, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.19628277700394392  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  15 / 20\n",
            "----------\n",
            "Train loss =  0.21573536847418512  | Train acc =  tensor(0.9215, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.20272063568700105  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  16 / 20\n",
            "----------\n",
            "Train loss =  0.20392488725810198  | Train acc =  tensor(0.9327, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.20025406416971236  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  17 / 20\n",
            "----------\n",
            "Train loss =  0.1869606688912762  | Train acc =  tensor(0.9338, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1893130669486709  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  18 / 20\n",
            "----------\n",
            "Train loss =  0.19161948536615275  | Train acc =  tensor(0.9336, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.1663146664504893  | Val acc =  tensor(0.9540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  19 / 20\n",
            "----------\n",
            "Train loss =  0.16042082046556194  | Train acc =  tensor(0.9433, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.18173644074704498  | Val acc =  tensor(0.9440, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  20 / 20\n",
            "----------\n",
            "Train loss =  0.1643646358463325  | Train acc =  tensor(0.9430, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.21294013923034072  | Val acc =  tensor(0.9380, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4CgubNn1yiV",
        "outputId": "a79258ac-b134-4514-c0cf-4c30cdce39d9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 20\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.16269637101564055  | Train acc =  tensor(0.9420, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.16963850031606853  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 20\n",
            "----------\n",
            "Train loss =  0.1495719695387528  | Train acc =  tensor(0.9486, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.17750404123216867  | Val acc =  tensor(0.9540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 20\n",
            "----------\n",
            "Train loss =  0.1425380244039609  | Train acc =  tensor(0.9503, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.18898114070179872  | Val acc =  tensor(0.9440, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 20\n",
            "----------\n",
            "Train loss =  0.13377385173940606  | Train acc =  tensor(0.9532, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.16423410893185064  | Val acc =  tensor(0.9560, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 20\n",
            "----------\n",
            "Train loss =  0.13067547864776258  | Train acc =  tensor(0.9534, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.22960378712741658  | Val acc =  tensor(0.9420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 20\n",
            "----------\n",
            "Train loss =  0.13017839455584945  | Train acc =  tensor(0.9547, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.21885978005593643  | Val acc =  tensor(0.9360, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 20\n",
            "----------\n",
            "Train loss =  0.13384154772832554  | Train acc =  tensor(0.9569, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.18035993253579363  | Val acc =  tensor(0.9540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 20\n",
            "----------\n",
            "Train loss =  0.12166299033713968  | Train acc =  tensor(0.9578, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.17976284940959886  | Val acc =  tensor(0.9520, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 20\n",
            "----------\n",
            "Train loss =  0.11591452056247938  | Train acc =  tensor(0.9578, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.18254874352714978  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 20\n",
            "----------\n",
            "Train loss =  0.11308995107657205  | Train acc =  tensor(0.9624, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2030986747413408  | Val acc =  tensor(0.9500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  11 / 20\n",
            "----------\n",
            "Train loss =  0.10703546992552124  | Train acc =  tensor(0.9640, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.24631764899822883  | Val acc =  tensor(0.9440, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  12 / 20\n",
            "----------\n",
            "Train loss =  0.10998964408679446  | Train acc =  tensor(0.9631, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.16466694202972576  | Val acc =  tensor(0.9500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  13 / 20\n",
            "----------\n",
            "Train loss =  0.09541252884218654  | Train acc =  tensor(0.9699, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.22861186423688196  | Val acc =  tensor(0.9340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  14 / 20\n",
            "----------\n",
            "Train loss =  0.0938444557989136  | Train acc =  tensor(0.9699, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.16572196714696474  | Val acc =  tensor(0.9600, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  15 / 20\n",
            "----------\n",
            "Train loss =  0.09069867779321053  | Train acc =  tensor(0.9664, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.21734604833181947  | Val acc =  tensor(0.9500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  16 / 20\n",
            "----------\n",
            "Train loss =  0.0879606044523102  | Train acc =  tensor(0.9681, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.15721120726084337  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  17 / 20\n",
            "----------\n",
            "Train loss =  0.07950156594474109  | Train acc =  tensor(0.9729, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2009851983311819  | Val acc =  tensor(0.9560, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  18 / 20\n",
            "----------\n",
            "Train loss =  0.08580822956902166  | Train acc =  tensor(0.9705, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.202549460955197  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  19 / 20\n",
            "----------\n",
            "Train loss =  0.07788432684076177  | Train acc =  tensor(0.9749, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.19447779895563144  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  20 / 20\n",
            "----------\n",
            "Train loss =  0.06376442594020709  | Train acc =  tensor(0.9778, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2182807110802969  | Val acc =  tensor(0.9520, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfm0vDLO2_ip",
        "outputId": "45eeada4-7b07-4d1d-df2f-2567b0ba1add"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 20\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.06919176804449148  | Train acc =  tensor(0.9743, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2087714962544851  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 20\n",
            "----------\n",
            "Train loss =  0.06899278540006289  | Train acc =  tensor(0.9767, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.24543361250835005  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 20\n",
            "----------\n",
            "Train loss =  0.07084797564328904  | Train acc =  tensor(0.9729, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.27790964976884425  | Val acc =  tensor(0.9460, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 20\n",
            "----------\n",
            "Train loss =  0.06650793806606174  | Train acc =  tensor(0.9773, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.19686450634617358  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 20\n",
            "----------\n",
            "Train loss =  0.06210700165867065  | Train acc =  tensor(0.9778, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.24512131939991377  | Val acc =  tensor(0.9520, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 20\n",
            "----------\n",
            "Train loss =  0.06899652503854976  | Train acc =  tensor(0.9752, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.24933970080746803  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 20\n",
            "----------\n",
            "Train loss =  0.05883264982880894  | Train acc =  tensor(0.9798, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.20800341604626738  | Val acc =  tensor(0.9520, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 20\n",
            "----------\n",
            "Train loss =  0.05928009186567717  | Train acc =  tensor(0.9820, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.20553362602367997  | Val acc =  tensor(0.9500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 20\n",
            "----------\n",
            "Train loss =  0.06151386876576934  | Train acc =  tensor(0.9806, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.28196413470141124  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 20\n",
            "----------\n",
            "Train loss =  0.058379190699493495  | Train acc =  tensor(0.9793, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.23174503582413308  | Val acc =  tensor(0.9500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  11 / 20\n",
            "----------\n",
            "Train loss =  0.051966535965098495  | Train acc =  tensor(0.9833, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2718312652723398  | Val acc =  tensor(0.9520, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  12 / 20\n",
            "----------\n",
            "Train loss =  0.047462964489680244  | Train acc =  tensor(0.9829, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2490297893891693  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  13 / 20\n",
            "----------\n",
            "Train loss =  0.04827046162891849  | Train acc =  tensor(0.9837, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.24765899114572676  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  14 / 20\n",
            "----------\n",
            "Train loss =  0.04125440382384709  | Train acc =  tensor(0.9855, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.21030538881313987  | Val acc =  tensor(0.9580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  15 / 20\n",
            "----------\n",
            "Train loss =  0.047223150171841595  | Train acc =  tensor(0.9809, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2280913463619072  | Val acc =  tensor(0.9500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  16 / 20\n",
            "----------\n",
            "Train loss =  0.039416461978548506  | Train acc =  tensor(0.9866, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2695326074717741  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  17 / 20\n",
            "----------\n",
            "Train loss =  0.041346103961421896  | Train acc =  tensor(0.9848, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.23196010843821568  | Val acc =  tensor(0.9560, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  18 / 20\n",
            "----------\n",
            "Train loss =  0.03829831757844148  | Train acc =  tensor(0.9870, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2759882382597425  | Val acc =  tensor(0.9480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  19 / 20\n",
            "----------\n",
            "Train loss =  0.04033647545710191  | Train acc =  tensor(0.9859, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2526927029248327  | Val acc =  tensor(0.9540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  20 / 20\n",
            "----------\n",
            "Train loss =  0.03946711927957353  | Train acc =  tensor(0.9873, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.22247126876027323  | Val acc =  tensor(0.9600, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FowX65XKmiMY",
        "outputId": "1f047592-5b1e-43b9-8688-6e4651729df0"
      },
      "source": [
        "name = 'QC_V4Simple'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV4, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV4, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV4.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.720185755899078  | Train acc =  tensor(0.7671, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.16436817264184356  | Val acc =  tensor(0.9640, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 10\n",
            "----------\n",
            "Train loss =  0.18504050008037634  | Train acc =  tensor(0.9536, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.14544656313955784  | Val acc =  tensor(0.9700, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 10\n",
            "----------\n",
            "Train loss =  0.08617780166433046  | Train acc =  tensor(0.9809, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.13785107189323753  | Val acc =  tensor(0.9720, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 10\n",
            "----------\n",
            "Train loss =  0.04815776572067138  | Train acc =  tensor(0.9903, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.19400997803313658  | Val acc =  tensor(0.9680, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 10\n",
            "----------\n",
            "Train loss =  0.028891878581077557  | Train acc =  tensor(0.9945, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.16718742474040482  | Val acc =  tensor(0.9700, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 10\n",
            "----------\n",
            "Train loss =  0.018081230694177556  | Train acc =  tensor(0.9961, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.17152967311267275  | Val acc =  tensor(0.9740, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 10\n",
            "----------\n",
            "Train loss =  0.010555224736869248  | Train acc =  tensor(0.9978, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.24561461155826692  | Val acc =  tensor(0.9620, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 10\n",
            "----------\n",
            "Train loss =  0.010552799205257618  | Train acc =  tensor(0.9985, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2382827382243704  | Val acc =  tensor(0.9680, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 10\n",
            "----------\n",
            "Train loss =  0.008846076346977412  | Train acc =  tensor(0.9985, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.22144226940145018  | Val acc =  tensor(0.9700, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 10\n",
            "----------\n",
            "Train loss =  0.012494684760703853  | Train acc =  tensor(0.9978, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.2784933569455461  | Val acc =  tensor(0.9600, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}