{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QC_BERT_Ext.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d22a57afb3ea4a9cb082fea5bc4ee55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0950c15ec51e4bc9ba97215fdedff043",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9ec6faa7d3a54e40b706adb850c6d47c",
              "IPY_MODEL_78e21824d72140c2aa14fdded7673d00"
            ]
          }
        },
        "0950c15ec51e4bc9ba97215fdedff043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ec6faa7d3a54e40b706adb850c6d47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95d111a0ee8149c6bdb92886e08a36ee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8e71e6ee3574afe954c3bf22f791dd4"
          }
        },
        "78e21824d72140c2aa14fdded7673d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_408a751eb809407f8bdedc11b74be47d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 283kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac01f2f1f0254c779c05d8e4dd9d7faa"
          }
        },
        "95d111a0ee8149c6bdb92886e08a36ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8e71e6ee3574afe954c3bf22f791dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "408a751eb809407f8bdedc11b74be47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac01f2f1f0254c779c05d8e4dd9d7faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c94ce09c0ab4bc0be77e87ed393d5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ba1c6b188774949a6d3848fff7408e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97ed59b86874404bad24a62ce2857318",
              "IPY_MODEL_a20e2df6d52c4f5589ec950d7c831cd4"
            ]
          }
        },
        "7ba1c6b188774949a6d3848fff7408e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97ed59b86874404bad24a62ce2857318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8739bf30206348319f11534c71e11151",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b4d96c33af7428f82b79811cfea0699"
          }
        },
        "a20e2df6d52c4f5589ec950d7c831cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_419dfb60c0014a5ca243ca8e72069592",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 457B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47498da734f54bb787c53bdd8af2425e"
          }
        },
        "8739bf30206348319f11534c71e11151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b4d96c33af7428f82b79811cfea0699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "419dfb60c0014a5ca243ca8e72069592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47498da734f54bb787c53bdd8af2425e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f4544697f494baa97774fe2833119ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_302cbd2c34e64696a8951335223098bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9984722ba93467f90a33517581408f0",
              "IPY_MODEL_553096ef5c1948c68e501e5a8959f7fb"
            ]
          }
        },
        "302cbd2c34e64696a8951335223098bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9984722ba93467f90a33517581408f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69acfc7f00784a9d8263966d82c1bdfe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3979627fbc684706b30f5505f27a8139"
          }
        },
        "553096ef5c1948c68e501e5a8959f7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd42cb28f01a48758d8c8619d02c148b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:11&lt;00:00, 38.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_757775c7ca01493fbff0307bcb7a3b85"
          }
        },
        "69acfc7f00784a9d8263966d82c1bdfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3979627fbc684706b30f5505f27a8139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd42cb28f01a48758d8c8619d02c148b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "757775c7ca01493fbff0307bcb7a3b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qd9JpWyPVpy",
        "outputId": "e62e5065-b96e-4b22-90ed-f6962a361030"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YRbR_ekPd69"
      },
      "source": [
        "data_path = \"/content/gdrive/My Drive/Data/\"\n",
        "model_path = \"/content/gdrive/My Drive/Models/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__l3TvSoPnGE",
        "outputId": "0b3564d6-c1f5-4188-8bde-ffa3862f3781"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 13.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 18.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 9.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 29.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3496070290a4569cc6baa18bfda2ab5edb65e42c2791fa73f314be6c30609101\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5kWWbBzQb61"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MATrntszJ8bD"
      },
      "source": [
        "RANDOM_SEED = 0\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTkNv-AiQohs"
      },
      "source": [
        "train_file = open(data_path + 'QC_train.txt')\n",
        "test_file = open(data_path + 'QC_test.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRS1FvLJS0pu"
      },
      "source": [
        "def get_df(inp_file):\n",
        "  return pd.DataFrame(inp_file.readlines(), columns=['Question'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65-xvQwHQ9vV"
      },
      "source": [
        "train_data = get_df(train_file)\n",
        "test_data = get_df(test_file)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "pR7_F-pIRPiE",
        "outputId": "2be50975-8070-4954-9a96-98c1bb189442"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DESC:manner How did serfdom develop in and the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTY:cremat What films featured the character ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DESC:manner How can I find a list of celebriti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTY:animal What fowl grabs the spotlight afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBR:exp What is the full form of .com ?\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question\n",
              "0  DESC:manner How did serfdom develop in and the...\n",
              "1  ENTY:cremat What films featured the character ...\n",
              "2  DESC:manner How can I find a list of celebriti...\n",
              "3  ENTY:animal What fowl grabs the spotlight afte...\n",
              "4         ABBR:exp What is the full form of .com ?\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Kexlq1SqE7"
      },
      "source": [
        "def improve_df(df):\n",
        "  df['Type'] = df['Question'].apply(lambda s: s.split(' ', 1)[0])\n",
        "  df['Question'] = df['Question'].apply(lambda s: s.split(' ', 1)[1])\n",
        "  df['TypeSimple'] = df['Type'].apply(lambda s: s.split(':')[0])\n",
        "  df['TypeExtended'] = df['Type'].apply(lambda s: s.split(':')[1])\n",
        "  return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_053WWURSJl"
      },
      "source": [
        "train_data = improve_df(train_data)\n",
        "test_data = improve_df(test_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "eA3Txee1TQ3u",
        "outputId": "fab086ae-17f8-4adc-db5f-2feb5c73c8a2"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>DESC:manner</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle...</td>\n",
              "      <td>ENTY:cremat</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>cremat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>DESC:manner</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>ENTY:animal</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>animal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?\\n</td>\n",
              "      <td>ABBR:exp</td>\n",
              "      <td>ABBR</td>\n",
              "      <td>exp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ... TypeExtended\n",
              "0  How did serfdom develop in and then leave Russ...  ...       manner\n",
              "1  What films featured the character Popeye Doyle...  ...       cremat\n",
              "2  How can I find a list of celebrities ' real na...  ...       manner\n",
              "3  What fowl grabs the spotlight after the Chines...  ...       animal\n",
              "4                  What is the full form of .com ?\\n  ...          exp\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Os0yct15Tfwg",
        "outputId": "d99d20de-94e1-4904-e8f9-cd336b6292eb"
      },
      "source": [
        "test_data.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>500</td>\n",
              "      <td>42</td>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>What color does litmus paper turn when it come...</td>\n",
              "      <td>DESC:def</td>\n",
              "      <td>DESC</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>138</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Question  ... TypeExtended\n",
              "count                                                 500  ...          500\n",
              "unique                                                500  ...           39\n",
              "top     What color does litmus paper turn when it come...  ...          def\n",
              "freq                                                    1  ...          123\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "BWxrGtqbUEOR",
        "outputId": "0802ff0a-f350-4538-fc11-b136511bad1b"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How far is it from Denver to Aspen ?\\n</td>\n",
              "      <td>NUM:dist</td>\n",
              "      <td>NUM</td>\n",
              "      <td>dist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What county is Modesto , California in ?\\n</td>\n",
              "      <td>LOC:city</td>\n",
              "      <td>LOC</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who was Galileo ?\\n</td>\n",
              "      <td>HUM:desc</td>\n",
              "      <td>HUM</td>\n",
              "      <td>desc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is an atom ?\\n</td>\n",
              "      <td>DESC:def</td>\n",
              "      <td>DESC</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When did Hawaii become a state ?\\n</td>\n",
              "      <td>NUM:date</td>\n",
              "      <td>NUM</td>\n",
              "      <td>date</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Question      Type TypeSimple TypeExtended\n",
              "0      How far is it from Denver to Aspen ?\\n  NUM:dist        NUM         dist\n",
              "1  What county is Modesto , California in ?\\n  LOC:city        LOC         city\n",
              "2                         Who was Galileo ?\\n  HUM:desc        HUM         desc\n",
              "3                         What is an atom ?\\n  DESC:def       DESC          def\n",
              "4          When did Hawaii become a state ?\\n  NUM:date        NUM         date"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "UyZFe8cLUHfz",
        "outputId": "e5e9e958-3581-48dc-bf6e-41c7bcf8157c"
      },
      "source": [
        "train_data.append(test_data).describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5952</td>\n",
              "      <td>5952</td>\n",
              "      <td>5952</td>\n",
              "      <td>5952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5871</td>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>What is Columbia Tristar 's phone number ?\\n</td>\n",
              "      <td>HUM:ind</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>1017</td>\n",
              "      <td>1344</td>\n",
              "      <td>1017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ... TypeExtended\n",
              "count                                           5952  ...         5952\n",
              "unique                                          5871  ...           47\n",
              "top     What is Columbia Tristar 's phone number ?\\n  ...          ind\n",
              "freq                                               3  ...         1017\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNAG3399OQ6E"
      },
      "source": [
        "TARGET_NAMES = train_data['TypeExtended'].unique().tolist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG8pBB8jUSGP"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC0kxtXQIH2N"
      },
      "source": [
        "def encode_tag(train_data, test_data, tag):\n",
        "  l_enc = LabelEncoder()\n",
        "  l_enc.fit(pd.Series(train_data[tag].tolist() + test_data[tag].tolist()).values)\n",
        "  return l_enc.transform(train_data[tag].values), l_enc.transform(test_data[tag].values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy7BJ_gGJGnE"
      },
      "source": [
        "tag = 'Type'\n",
        "train_data[tag], test_data[tag] = encode_tag(train_data, test_data, tag)\n",
        "tag = 'TypeSimple'\n",
        "train_data[tag], test_data[tag] = encode_tag(train_data, test_data, tag)\n",
        "tag = 'TypeExtended'\n",
        "train_data[tag], test_data[tag] = encode_tag(train_data, test_data, tag)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "mwcviZ-rJUhd",
        "outputId": "11f3cd65-c00f-4ea7-c462-91d2c1030ddd"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Type</th>\n",
              "      <th>TypeSimple</th>\n",
              "      <th>TypeExtended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?\\n</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ...  TypeExtended\n",
              "0  How did serfdom develop in and then leave Russ...  ...            23\n",
              "1  What films featured the character Popeye Doyle...  ...             8\n",
              "2  How can I find a list of celebrities ' real na...  ...            23\n",
              "3  What fowl grabs the spotlight after the Chines...  ...             1\n",
              "4                  What is the full form of .com ?\\n  ...            16\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNmdlghsJXyD",
        "outputId": "39a1a797-1681-4205-df44-a3e4ac4d1224"
      },
      "source": [
        "train_data.columns"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Question', 'Type', 'TypeSimple', 'TypeExtended'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu8Zh4SVJaUQ",
        "outputId": "880ef971-b763-4edd-f035-7b0bb8fb4424"
      },
      "source": [
        "train_data['TypeExtended'].unique()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23,  8,  1, 16, 19, 18, 42, 11, 10, 32, 15, 36, 12,  6, 27, 22, 33,\n",
              "       17,  7,  5, 41,  3,  2, 13, 25, 24, 31, 29, 37, 35, 30, 39, 44, 20,\n",
              "        0, 34, 46, 21, 28,  4, 14, 40, 38, 26, 43, 45,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJdJtM7MJeEP"
      },
      "source": [
        "SRC_COL = 'Question'\n",
        "TRG_COL = 'TypeExtended'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0fNT9MEJvTc",
        "outputId": "356c0307-27c1-4f48-8610-9542adec08ee"
      },
      "source": [
        "TARGETS = train_data[TRG_COL].unique().tolist()\n",
        "print(TARGETS)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[23, 8, 1, 16, 19, 18, 42, 11, 10, 32, 15, 36, 12, 6, 27, 22, 33, 17, 7, 5, 41, 3, 2, 13, 25, 24, 31, 29, 37, 35, 30, 39, 44, 20, 0, 34, 46, 21, 28, 4, 14, 40, 38, 26, 43, 45, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g82cobeQOk9Z"
      },
      "source": [
        "TARGET_DICT = dict()\r\n",
        "for i in range(len(TARGET_NAMES)):\r\n",
        "  TARGET_DICT[TARGETS[i]] = TARGET_NAMES[i]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkyqEkajO8xZ",
        "outputId": "08989fe7-755b-4496-aca5-e1fb14ee4951"
      },
      "source": [
        "TARGET_DICT"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'abb',\n",
              " 1: 'animal',\n",
              " 2: 'body',\n",
              " 3: 'city',\n",
              " 4: 'code',\n",
              " 5: 'color',\n",
              " 6: 'count',\n",
              " 7: 'country',\n",
              " 8: 'cremat',\n",
              " 9: 'currency',\n",
              " 10: 'date',\n",
              " 11: 'def',\n",
              " 12: 'desc',\n",
              " 13: 'dismed',\n",
              " 14: 'dist',\n",
              " 15: 'event',\n",
              " 16: 'exp',\n",
              " 17: 'food',\n",
              " 18: 'gr',\n",
              " 19: 'ind',\n",
              " 20: 'instru',\n",
              " 21: 'lang',\n",
              " 22: 'letter',\n",
              " 23: 'manner',\n",
              " 24: 'money',\n",
              " 25: 'mount',\n",
              " 26: 'ord',\n",
              " 27: 'other',\n",
              " 28: 'perc',\n",
              " 29: 'period',\n",
              " 30: 'plant',\n",
              " 31: 'product',\n",
              " 32: 'reason',\n",
              " 33: 'religion',\n",
              " 34: 'speed',\n",
              " 35: 'sport',\n",
              " 36: 'state',\n",
              " 37: 'substance',\n",
              " 38: 'symbol',\n",
              " 39: 'techmeth',\n",
              " 40: 'temp',\n",
              " 41: 'termeq',\n",
              " 42: 'title',\n",
              " 43: 'veh',\n",
              " 44: 'volsize',\n",
              " 45: 'weight',\n",
              " 46: 'word'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-akN7_t-JymN"
      },
      "source": [
        "BERT_MODEL_NAME = 'bert-base-cased' "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d22a57afb3ea4a9cb082fea5bc4ee55f",
            "0950c15ec51e4bc9ba97215fdedff043",
            "9ec6faa7d3a54e40b706adb850c6d47c",
            "78e21824d72140c2aa14fdded7673d00",
            "95d111a0ee8149c6bdb92886e08a36ee",
            "a8e71e6ee3574afe954c3bf22f791dd4",
            "408a751eb809407f8bdedc11b74be47d",
            "ac01f2f1f0254c779c05d8e4dd9d7faa"
          ]
        },
        "id": "-JhfuHcCKCzy",
        "outputId": "388c4168-751a-401f-ab66-3c62f27fc87a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d22a57afb3ea4a9cb082fea5bc4ee55f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48njcQq_KEmD",
        "outputId": "47cc56c8-569a-455c-8cae-bcd5b0f21653"
      },
      "source": [
        "token_lengths = []\n",
        "for sent in train_data[SRC_COL]:\n",
        "  tokens = tokenizer.encode(sent, max_length=tokenizer.max_model_input_sizes[BERT_MODEL_NAME])\n",
        "  token_lengths.append(len(tokens))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEJ_47IgKtcf"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgXKNAm2LBIT"
      },
      "source": [
        "rcParams['figure.figsize'] = 8, 6"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "1ZelRv7BKkV4",
        "outputId": "a3661c51-4924-41fa-9668-aa4ae3fb7c84"
      },
      "source": [
        "sns.distplot(token_lengths)\n",
        "plt.xlim([0, tokenizer.max_model_input_sizes[BERT_MODEL_NAME] // 10])\n",
        "plt.xlabel('Token count')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Token count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1hmW44LK3u"
      },
      "source": [
        "MAX_LEN = 32"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qLbePSnLOH2"
      },
      "source": [
        "class QuestionsDataset(Dataset):\n",
        "  def __init__(self, src_list, trg_list, tokenizer, MAX_LEN):\n",
        "    self.src_list = src_list\n",
        "    self.trg_list = trg_list\n",
        "    self.tokenizer = tokenizer\n",
        "    self.MAX_LEN = MAX_LEN\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.src_list)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    src = str(self.src_list[item])\n",
        "    trg = self.trg_list[item]\n",
        "    encoder = tokenizer.encode_plus(\n",
        "      src, add_special_tokens=True,\n",
        "      max_length=self.MAX_LEN,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    return {'src': src, 'input_ids': encoder['input_ids'].flatten(), 'attention_mask': encoder['attention_mask'].flatten(), 'trg': torch.tensor(trg, dtype=torch.long)}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uI6JqfTMDdr"
      },
      "source": [
        "def get_loader(df, tokenizer, MAX_LEN, BATCH_SIZE):\n",
        "  data = QuestionsDataset(src_list=df[SRC_COL].to_numpy(), trg_list=df[TRG_COL].to_numpy(), tokenizer=tokenizer, MAX_LEN=MAX_LEN)\n",
        "  loader = DataLoader(data, batch_size=BATCH_SIZE)\n",
        "  return loader"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_n7keQHMcDd"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = get_loader(train_data, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_loader = get_loader(test_data, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bztMwHUbM4RY",
        "outputId": "08169a56-cc11-48cd-e996-30b94e45c298"
      },
      "source": [
        "data = next(iter(train_loader))\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['trg'].shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 32])\n",
            "torch.Size([32, 32])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPVO2wH_NBeH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "4c94ce09c0ab4bc0be77e87ed393d5a7",
            "7ba1c6b188774949a6d3848fff7408e0",
            "97ed59b86874404bad24a62ce2857318",
            "a20e2df6d52c4f5589ec950d7c831cd4",
            "8739bf30206348319f11534c71e11151",
            "6b4d96c33af7428f82b79811cfea0699",
            "419dfb60c0014a5ca243ca8e72069592",
            "47498da734f54bb787c53bdd8af2425e",
            "6f4544697f494baa97774fe2833119ff",
            "302cbd2c34e64696a8951335223098bd",
            "d9984722ba93467f90a33517581408f0",
            "553096ef5c1948c68e501e5a8959f7fb",
            "69acfc7f00784a9d8263966d82c1bdfe",
            "3979627fbc684706b30f5505f27a8139",
            "bd42cb28f01a48758d8c8619d02c148b",
            "757775c7ca01493fbff0307bcb7a3b85"
          ]
        },
        "outputId": "70f63698-bd50-4021-b1a6-b07e32efb954"
      },
      "source": [
        "bert = BertModel.from_pretrained(BERT_MODEL_NAME)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c94ce09c0ab4bc0be77e87ed393d5a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f4544697f494baa97774fe2833119ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuDbZa1WNE4G"
      },
      "source": [
        "res = bert(input_ids=data['input_ids'], attention_mask=data['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IklwYiPuQoYi",
        "outputId": "4ae33ca0-7227-4393-dc9c-360765165e88"
      },
      "source": [
        "res[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C_jKY79R8Lf",
        "outputId": "87091f99-10d1-4f19-ff3a-4ad735ea8f54"
      },
      "source": [
        "res[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwtlSWIvdVdp"
      },
      "source": [
        "after_lin = nn.Linear(bert.config.hidden_size, bert.config.hidden_size)(res[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIaS5u2ZdaBu",
        "outputId": "82419487-2449-4154-a22c-29869690ec81"
      },
      "source": [
        "after_lin.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmSBeptldflV",
        "outputId": "e79b4d97-dbc8-4f14-c777-3fadd825575b"
      },
      "source": [
        "nn.Linear(bert.config.hidden_size, len(TARGETS))(after_lin).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 47])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTccT3pLSdcH"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2out = nn.Linear(self.inp2emb.config.hidden_size, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
        "    emb = self.drop(emb)\n",
        "    out = self.emb2out(emb)\n",
        "    return out"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkIl8Jy5cgir"
      },
      "source": [
        "classifier = Classifier(bert, 0.3, len(TARGETS))\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBWtBSc_df2j"
      },
      "source": [
        "EPOCHS = 10\n",
        "optim = AdamW(classifier.parameters(), lr=2e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meWPSGdedsWa"
      },
      "source": [
        "class ClassifierV2(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags):\n",
        "    super(ClassifierV2, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2hid = nn.Linear(self.inp2emb.config.hidden_size, self.inp2emb.config.hidden_size)\n",
        "    self.hid2out = nn.Linear(self.inp2emb.config.hidden_size, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
        "    emb = self.drop(emb)\n",
        "    hid = self.emb2hid(emb)\n",
        "    out = self.hid2out(hid)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0djU_xreAvQ"
      },
      "source": [
        "classifierV2 = ClassifierV2(bert, 0.3, len(TARGETS))\n",
        "classifierV2 = classifierV2.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjxfbnqhectA"
      },
      "source": [
        "EPOCHS = 10\n",
        "optim = AdamW(classifierV2.parameters(), lr=2e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMqL_qFnxFSQ"
      },
      "source": [
        "class ClassifierV3(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags, hid_dim, num_lay):\n",
        "    super(ClassifierV3, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2hid = nn.GRU(self.inp2emb.config.hidden_size, hid_dim, num_layers=num_lay, bidirectional=True, batch_first=True, dropout=p)\n",
        "    self.hid2out = nn.Linear(hid_dim * 2, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    with torch.no_grad():\n",
        "      emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "    h, hid = self.emb2hid(emb)\n",
        "    hid = self.drop(torch.cat((hid[-2,:,:], hid[-1,:,:]), dim=1))\n",
        "    out = self.hid2out(hid)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06JaSW9oxI_J"
      },
      "source": [
        "classifierV3 = ClassifierV3(bert, 0.3, len(TARGETS), 256, 2)\n",
        "classifierV3 = classifierV3.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGaPQUNleGCg",
        "outputId": "c601034e-1f93-4b2c-84dd-21d00b9d8feb"
      },
      "source": [
        "sum(p.numel() for p in classifierV3.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111093039"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmYnu8KrylCV"
      },
      "source": [
        "for name, param in classifierV3.named_parameters():\n",
        "  if name.startswith('inp2emb'):\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0NH7CUGeMVe",
        "outputId": "d0c41c4d-db44-46bc-d476-e434ec560c80"
      },
      "source": [
        "sum(p.numel() for p in classifierV3.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2782767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKJ82eycyr_N"
      },
      "source": [
        "EPOCHS = 40\n",
        "optim = AdamW(classifierV3.parameters(), lr=3e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97tjeVpTHM5i"
      },
      "source": [
        "class ClassifierV4(nn.Module):\n",
        "  def __init__(self, bert, p, num_tags, hid_dim, num_lay):\n",
        "    super(ClassifierV4, self).__init__()\n",
        "    self.inp2emb = bert\n",
        "    self.drop = nn.Dropout(p=p)\n",
        "    self.emb2hid0 = nn.Linear(self.inp2emb.config.hidden_size, hid_dim * 2)\n",
        "    self.emb2hid = nn.GRU(self.inp2emb.config.hidden_size, hid_dim, num_layers=num_lay, bidirectional=True, batch_first=True, dropout=p)\n",
        "    self.hid2out = nn.Linear(hid_dim * 2, num_tags)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    emb = self.inp2emb(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    hid0 = self.emb2hid0(emb[1])\n",
        "    hid0 = torch.cat((hid0, hid0), dim=1).reshape(4, hid0.size(0), hid0.size(1) // 2)\n",
        "    h, hid = self.emb2hid(emb[0], hid0)\n",
        "    hid = self.drop(torch.cat((hid[-2,:,:], hid[-1,:,:]), dim=1))\n",
        "    out = self.hid2out(hid)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Q0QbO2HY-W"
      },
      "source": [
        "classifierV4 = ClassifierV4(bert, 0.3, len(TARGETS), 64, 2)\n",
        "classifierV4 = classifierV4.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hutCtOnNHa3c"
      },
      "source": [
        "EPOCHS = 10\n",
        "optim = AdamW(classifierV4.parameters(), lr=2e-5)\n",
        "crit = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDxYKnsOdtUR"
      },
      "source": [
        "def train_epoch(model, loader, crit, optim, device, num_ex):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct = 0\n",
        "\n",
        "  for data in loader:\n",
        "    input_ids = data['input_ids'].to(device)\n",
        "    attention_mask = data['attention_mask'].to(device)\n",
        "    trg = data['trg'].to(device)\n",
        "\n",
        "    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    _, pred = torch.max(out, dim=1)\n",
        "    loss = crit(out, trg)\n",
        "    correct += torch.sum(pred == trg)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "  \n",
        "  return correct.double() / num_ex, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWw0JMXfiQhE"
      },
      "source": [
        "def eval(model, loader, crit, device, num_ex):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in loader:\n",
        "      input_ids = data['input_ids'].to(device)\n",
        "      attention_mask = data['attention_mask'].to(device)\n",
        "      trg = data['trg'].to(device)\n",
        "\n",
        "      out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      _, pred = torch.max(out, dim=1)\n",
        "      loss = crit(out, trg)\n",
        "      correct += torch.sum(pred == trg)\n",
        "      losses.append(loss.item())\n",
        "  \n",
        "  return correct.double() / num_ex, np.mean(losses)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nvNRTsek6ox",
        "outputId": "9fde9453-6656-4966-e503-e049d5c81845"
      },
      "source": [
        "name = 'QC_StandardExtended'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifier, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifier, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifier.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  2.659545139262551  | Train acc =  tensor(0.3912, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.6921062022447586  | Val acc =  tensor(0.6620, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 10\n",
            "----------\n",
            "Train loss =  1.1818803531384607  | Train acc =  tensor(0.7656, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9117884486913681  | Val acc =  tensor(0.8060, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 10\n",
            "----------\n",
            "Train loss =  0.5896115282997053  | Train acc =  tensor(0.8876, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7058103736490011  | Val acc =  tensor(0.8500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 10\n",
            "----------\n",
            "Train loss =  0.3395491446319379  | Train acc =  tensor(0.9409, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5711104162037373  | Val acc =  tensor(0.8780, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 10\n",
            "----------\n",
            "Train loss =  0.19566298194491027  | Train acc =  tensor(0.9685, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5097201680764556  | Val acc =  tensor(0.9060, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 10\n",
            "----------\n",
            "Train loss =  0.12374582953685731  | Train acc =  tensor(0.9820, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.4724054578691721  | Val acc =  tensor(0.9180, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 10\n",
            "----------\n",
            "Train loss =  0.07943173742455523  | Train acc =  tensor(0.9884, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.4353148313239217  | Val acc =  tensor(0.9260, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 10\n",
            "----------\n",
            "Train loss =  0.049250640348144616  | Train acc =  tensor(0.9943, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.46982717840000987  | Val acc =  tensor(0.9180, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 10\n",
            "----------\n",
            "Train loss =  0.026029680765707764  | Train acc =  tensor(0.9972, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.44246759510133415  | Val acc =  tensor(0.9300, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 10\n",
            "----------\n",
            "Train loss =  0.018588074536079115  | Train acc =  tensor(0.9983, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.44797726289834827  | Val acc =  tensor(0.9280, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0cULJDkMJbd",
        "outputId": "522e3871-b9bc-4e0d-e47a-f3dc040bf885"
      },
      "source": [
        "classifier.load_state_dict(torch.load(model_path + 'QC_StandardExtended.pt'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO1ATQGfM7PF"
      },
      "source": [
        "def classify(model, sent):\r\n",
        "  encoded = tokenizer.encode_plus(sent, max_length=MAX_LEN, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\r\n",
        "  input_ids = encoded['input_ids'].to(device)\r\n",
        "  attention_mask = encoded['attention_mask'].to(device)\r\n",
        "\r\n",
        "  out = model(input_ids, attention_mask)\r\n",
        "  _, pred = torch.max(out, dim=1)\r\n",
        "\r\n",
        "  return TARGET_DICT[pred.item()]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "chSRMJquNpLt",
        "outputId": "21c9b84f-4f56-4425-953e-2c4b12480965"
      },
      "source": [
        "classify(classifier, 'What does NLP stand for ?')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'exp'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "m8yRTIc5PW6i",
        "outputId": "b191367f-27d0-4585-aa13-cbd6e04aee75"
      },
      "source": [
        "classify(classifier, 'What is the training strategy for recurrent neural networks ?')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'techmeth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "8Q90e_GZVaao",
        "outputId": "79dda32d-8bc5-4059-c414-bd661f0c2a82"
      },
      "source": [
        "classify(classifier, 'What is the training strategy for athletes ?')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'desc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "zoav9S5WPcoI",
        "outputId": "a66a9321-2fab-4e8b-b23b-d3b83bedb865"
      },
      "source": [
        "classify(classifier, 'What is the name of this monitor model ?')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'product'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "CQpmbWULUjMI",
        "outputId": "784fc4a3-fb8e-463f-ce56-98a21cfb5490"
      },
      "source": [
        "classify(classifier, 'What is the name of a company that produces this monitor model ?')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gr'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "LbPEp1YXPrDx",
        "outputId": "37012989-6601-460a-c4d1-52b52951ee53"
      },
      "source": [
        "classify(classifier, 'What is the highest point in the world ?')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mount'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "4DvHHiBcXZav",
        "outputId": "e78c0b3f-90aa-4316-91c1-838268e6eda1"
      },
      "source": [
        "classify(classifier, 'What is the distance to the Moon ?')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "vJXCXmoMXeR-",
        "outputId": "5d14be2f-bc12-453a-861f-bc2a69df8ba4"
      },
      "source": [
        "classify(classifier, 'How far is the Moon ?')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "IN7NOh2WYW_a",
        "outputId": "50d9cc57-2f7e-4907-8ab4-6badada95751"
      },
      "source": [
        "classify(classifier, 'How fast is a sports car ?')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'speed'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "T8yzffWsYct1",
        "outputId": "a684ad6f-c591-40af-b7f1-d0e9f819ba1d"
      },
      "source": [
        "classify(classifier, 'How expensive is a sports car ?')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'money'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "7BN1PbI5craU",
        "outputId": "51ece316-0089-4842-edc1-62ae5cf0823a"
      },
      "source": [
        "classify(classifier, 'How to reveal the truth ?')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'manner'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuOtyEMreiUB",
        "outputId": "ec1464ab-0cc3-48b8-db7d-9268729e8f58"
      },
      "source": [
        "name = 'QC_V2Extended'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV2, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV2, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV2.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  2.692896074021769  | Train acc =  tensor(0.3474, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.8448433205485344  | Val acc =  tensor(0.6380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 10\n",
            "----------\n",
            "Train loss =  1.3374563044274759  | Train acc =  tensor(0.7265, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.1521113105118275  | Val acc =  tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 10\n",
            "----------\n",
            "Train loss =  0.7145932967725553  | Train acc =  tensor(0.8509, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8616854082792997  | Val acc =  tensor(0.8160, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 10\n",
            "----------\n",
            "Train loss =  0.41126967092965083  | Train acc =  tensor(0.9213, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7047843337059021  | Val acc =  tensor(0.8640, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 10\n",
            "----------\n",
            "Train loss =  0.24218887078701057  | Train acc =  tensor(0.9538, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6149685150012374  | Val acc =  tensor(0.8760, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 10\n",
            "----------\n",
            "Train loss =  0.15298852816834088  | Train acc =  tensor(0.9710, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5896458863280714  | Val acc =  tensor(0.8800, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 10\n",
            "----------\n",
            "Train loss =  0.09445888579588885  | Train acc =  tensor(0.9853, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5313726421445608  | Val acc =  tensor(0.9100, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 10\n",
            "----------\n",
            "Train loss =  0.06091349306162338  | Train acc =  tensor(0.9903, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5508493750821799  | Val acc =  tensor(0.9160, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 10\n",
            "----------\n",
            "Train loss =  0.037082242166721506  | Train acc =  tensor(0.9939, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.49984052078798413  | Val acc =  tensor(0.9220, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 10\n",
            "----------\n",
            "Train loss =  0.026743158116686153  | Train acc =  tensor(0.9950, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.48234831099398434  | Val acc =  tensor(0.9120, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ4FX_xKhiiH",
        "outputId": "9e6976b7-cb44-4512-e00b-1736cfa55a25"
      },
      "source": [
        "name = 'QC_V2Extended'\n",
        "\n",
        "for epoch in range(EPOCHS // 2):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS // 2)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV2, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV2, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV2.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.015654575947688466  | Train acc =  tensor(0.9980, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5124211790971458  | Val acc =  tensor(0.9200, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 5\n",
            "----------\n",
            "Train loss =  0.014134246510132188  | Train acc =  tensor(0.9978, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5206314070383087  | Val acc =  tensor(0.9300, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 5\n",
            "----------\n",
            "Train loss =  0.008733684594650366  | Train acc =  tensor(0.9994, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5460166746634059  | Val acc =  tensor(0.9260, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 5\n",
            "----------\n",
            "Train loss =  0.00811946668664854  | Train acc =  tensor(0.9987, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5469755629892461  | Val acc =  tensor(0.9280, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 5\n",
            "----------\n",
            "Train loss =  0.00996241720334752  | Train acc =  tensor(0.9987, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5965003862511367  | Val acc =  tensor(0.9260, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5n41h13yw_z",
        "outputId": "57c276e9-9620-4dc8-c85f-adee0a6f2161"
      },
      "source": [
        "name = 'QC_V3Extended'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV3, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV3, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV3.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 40\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  3.2238857913435552  | Train acc =  tensor(0.1851, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  3.0610771626234055  | Val acc =  tensor(0.1140, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 40\n",
            "----------\n",
            "Train loss =  2.855712820911965  | Train acc =  tensor(0.2744, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  2.735644668340683  | Val acc =  tensor(0.4680, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 40\n",
            "----------\n",
            "Train loss =  2.5425728315498395  | Train acc =  tensor(0.4041, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  2.3518204763531685  | Val acc =  tensor(0.4580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 40\n",
            "----------\n",
            "Train loss =  2.2424894020571347  | Train acc =  tensor(0.4573, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  2.0784351155161858  | Val acc =  tensor(0.5520, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 40\n",
            "----------\n",
            "Train loss =  2.0077856479332463  | Train acc =  tensor(0.4958, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.855690911412239  | Val acc =  tensor(0.5820, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 40\n",
            "----------\n",
            "Train loss =  1.8194101121690538  | Train acc =  tensor(0.5308, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.6837531924247742  | Val acc =  tensor(0.5920, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 40\n",
            "----------\n",
            "Train loss =  1.6728630072889272  | Train acc =  tensor(0.5664, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.5669823475182056  | Val acc =  tensor(0.6000, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 40\n",
            "----------\n",
            "Train loss =  1.5504485644095125  | Train acc =  tensor(0.6003, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.4783167019486427  | Val acc =  tensor(0.6100, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 40\n",
            "----------\n",
            "Train loss =  1.4485968588388454  | Train acc =  tensor(0.6277, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.4040151722729206  | Val acc =  tensor(0.6220, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 40\n",
            "----------\n",
            "Train loss =  1.3567834914776318  | Train acc =  tensor(0.6532, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.3277526833117008  | Val acc =  tensor(0.6420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  11 / 40\n",
            "----------\n",
            "Train loss =  1.2888027108900728  | Train acc =  tensor(0.6684, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.2708303481340408  | Val acc =  tensor(0.6500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  12 / 40\n",
            "----------\n",
            "Train loss =  1.2257299803153814  | Train acc =  tensor(0.6871, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.2112365663051605  | Val acc =  tensor(0.6700, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  13 / 40\n",
            "----------\n",
            "Train loss =  1.159059120549096  | Train acc =  tensor(0.7058, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.1658597998321056  | Val acc =  tensor(0.6860, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  14 / 40\n",
            "----------\n",
            "Train loss =  1.1023143850571928  | Train acc =  tensor(0.7197, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.131169032305479  | Val acc =  tensor(0.6960, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  15 / 40\n",
            "----------\n",
            "Train loss =  1.0542011626979761  | Train acc =  tensor(0.7265, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.091747809201479  | Val acc =  tensor(0.7160, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  16 / 40\n",
            "----------\n",
            "Train loss =  1.0110484058396858  | Train acc =  tensor(0.7425, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.0594765059649944  | Val acc =  tensor(0.7240, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  17 / 40\n",
            "----------\n",
            "Train loss =  0.97580262338906  | Train acc =  tensor(0.7483, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.0333170033991337  | Val acc =  tensor(0.7240, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  18 / 40\n",
            "----------\n",
            "Train loss =  0.9330212949660787  | Train acc =  tensor(0.7606, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9993403740227222  | Val acc =  tensor(0.7320, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  19 / 40\n",
            "----------\n",
            "Train loss =  0.8870327950221056  | Train acc =  tensor(0.7715, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9661862291395664  | Val acc =  tensor(0.7400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  20 / 40\n",
            "----------\n",
            "Train loss =  0.8637444225319645  | Train acc =  tensor(0.7773, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9579903185367584  | Val acc =  tensor(0.7340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  21 / 40\n",
            "----------\n",
            "Train loss =  0.8305743849068358  | Train acc =  tensor(0.7830, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9298043474555016  | Val acc =  tensor(0.7500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  22 / 40\n",
            "----------\n",
            "Train loss =  0.8105953107451835  | Train acc =  tensor(0.7848, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.9155750200152397  | Val acc =  tensor(0.7540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  23 / 40\n",
            "----------\n",
            "Train loss =  0.7744200369070845  | Train acc =  tensor(0.7946, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8995469994843006  | Val acc =  tensor(0.7540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  24 / 40\n",
            "----------\n",
            "Train loss =  0.7447664331622988  | Train acc =  tensor(0.8034, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8649056106805801  | Val acc =  tensor(0.7660, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  25 / 40\n",
            "----------\n",
            "Train loss =  0.7215129492575663  | Train acc =  tensor(0.8032, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8537896629422903  | Val acc =  tensor(0.7580, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  26 / 40\n",
            "----------\n",
            "Train loss =  0.6965536510038097  | Train acc =  tensor(0.8135, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.842624893411994  | Val acc =  tensor(0.7780, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  27 / 40\n",
            "----------\n",
            "Train loss =  0.68219496832605  | Train acc =  tensor(0.8120, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8384585957974195  | Val acc =  tensor(0.7660, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  28 / 40\n",
            "----------\n",
            "Train loss =  0.655607561618961  | Train acc =  tensor(0.8239, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8134455271065235  | Val acc =  tensor(0.7820, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  29 / 40\n",
            "----------\n",
            "Train loss =  0.6364655900768369  | Train acc =  tensor(0.8281, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8006294928491116  | Val acc =  tensor(0.7760, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  30 / 40\n",
            "----------\n",
            "Train loss =  0.6095554605562087  | Train acc =  tensor(0.8355, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7780676670372486  | Val acc =  tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  31 / 40\n",
            "----------\n",
            "Train loss =  0.5938910306894292  | Train acc =  tensor(0.8375, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7780358642339706  | Val acc =  tensor(0.7880, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  32 / 40\n",
            "----------\n",
            "Train loss =  0.5735576008146966  | Train acc =  tensor(0.8432, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7673471048474312  | Val acc =  tensor(0.7980, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  33 / 40\n",
            "----------\n",
            "Train loss =  0.5586629583995942  | Train acc =  tensor(0.8478, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7578381858766079  | Val acc =  tensor(0.7940, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  34 / 40\n",
            "----------\n",
            "Train loss =  0.5441591851195396  | Train acc =  tensor(0.8547, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7360603138804436  | Val acc =  tensor(0.8060, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  35 / 40\n",
            "----------\n",
            "Train loss =  0.5226068586459633  | Train acc =  tensor(0.8558, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7229083627462387  | Val acc =  tensor(0.8080, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  36 / 40\n",
            "----------\n",
            "Train loss =  0.507636718059841  | Train acc =  tensor(0.8606, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7195873484015465  | Val acc =  tensor(0.8060, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  37 / 40\n",
            "----------\n",
            "Train loss =  0.4936868881272991  | Train acc =  tensor(0.8648, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7180494200438261  | Val acc =  tensor(0.7960, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  38 / 40\n",
            "----------\n",
            "Train loss =  0.47699924135765837  | Train acc =  tensor(0.8716, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7123626004904509  | Val acc =  tensor(0.8100, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  39 / 40\n",
            "----------\n",
            "Train loss =  0.4635007023724199  | Train acc =  tensor(0.8738, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6964868884533644  | Val acc =  tensor(0.8120, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  40 / 40\n",
            "----------\n",
            "Train loss =  0.448887944047214  | Train acc =  tensor(0.8745, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7125803139060736  | Val acc =  tensor(0.8140, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IruX1Cb36rll",
        "outputId": "30f060e3-ea4f-4577-d5fe-4f6b1b50123e"
      },
      "source": [
        "name = 'QC_V3Extended'\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV3, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV3, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV3.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 40\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.44032122660972917  | Train acc =  tensor(0.8795, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.701655887067318  | Val acc =  tensor(0.8100, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 40\n",
            "----------\n",
            "Train loss =  0.4206294379039118  | Train acc =  tensor(0.8837, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6909708678722382  | Val acc =  tensor(0.8160, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 40\n",
            "----------\n",
            "Train loss =  0.40823520214585535  | Train acc =  tensor(0.8877, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.680126715451479  | Val acc =  tensor(0.8160, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 40\n",
            "----------\n",
            "Train loss =  0.3967539683768624  | Train acc =  tensor(0.8947, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6733808219432831  | Val acc =  tensor(0.8200, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 40\n",
            "----------\n",
            "Train loss =  0.38055880999530267  | Train acc =  tensor(0.8967, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6673383954912424  | Val acc =  tensor(0.8180, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 40\n",
            "----------\n",
            "Train loss =  0.37444213376930585  | Train acc =  tensor(0.8988, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6750117745250463  | Val acc =  tensor(0.8200, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 40\n",
            "----------\n",
            "Train loss =  0.36081628242169905  | Train acc =  tensor(0.9063, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6710289921611547  | Val acc =  tensor(0.8180, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 40\n",
            "----------\n",
            "Train loss =  0.353512556232207  | Train acc =  tensor(0.9066, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6546614486724138  | Val acc =  tensor(0.8200, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 40\n",
            "----------\n",
            "Train loss =  0.3403202802465673  | Train acc =  tensor(0.9061, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6555954180657864  | Val acc =  tensor(0.8240, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 40\n",
            "----------\n",
            "Train loss =  0.33931163471867465  | Train acc =  tensor(0.9065, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6502884030342102  | Val acc =  tensor(0.8260, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  11 / 40\n",
            "----------\n",
            "Train loss =  0.32945812445634987  | Train acc =  tensor(0.9083, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.628679309040308  | Val acc =  tensor(0.8380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  12 / 40\n",
            "----------\n",
            "Train loss =  0.3214672884048774  | Train acc =  tensor(0.9123, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6448195390403271  | Val acc =  tensor(0.8240, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  13 / 40\n",
            "----------\n",
            "Train loss =  0.30972325782242577  | Train acc =  tensor(0.9156, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6397186126559973  | Val acc =  tensor(0.8280, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  14 / 40\n",
            "----------\n",
            "Train loss =  0.2990627741735232  | Train acc =  tensor(0.9176, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6237084493041039  | Val acc =  tensor(0.8320, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  15 / 40\n",
            "----------\n",
            "Train loss =  0.2967648939692486  | Train acc =  tensor(0.9180, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6204056870192289  | Val acc =  tensor(0.8380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  16 / 40\n",
            "----------\n",
            "Train loss =  0.27868968636146063  | Train acc =  tensor(0.9211, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6270107533782721  | Val acc =  tensor(0.8340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  17 / 40\n",
            "----------\n",
            "Train loss =  0.2832880777835149  | Train acc =  tensor(0.9222, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6412472557276487  | Val acc =  tensor(0.8340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  18 / 40\n",
            "----------\n",
            "Train loss =  0.2802417815951576  | Train acc =  tensor(0.9215, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6313130771741271  | Val acc =  tensor(0.8380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  19 / 40\n",
            "----------\n",
            "Train loss =  0.25492790742227206  | Train acc =  tensor(0.9320, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6222504554316401  | Val acc =  tensor(0.8380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  20 / 40\n",
            "----------\n",
            "Train loss =  0.2515091666657674  | Train acc =  tensor(0.9316, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6101332483813167  | Val acc =  tensor(0.8420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  21 / 40\n",
            "----------\n",
            "Train loss =  0.24698395608809956  | Train acc =  tensor(0.9320, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6235324693843722  | Val acc =  tensor(0.8320, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  22 / 40\n",
            "----------\n",
            "Train loss =  0.24192140186042116  | Train acc =  tensor(0.9325, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6216143677011132  | Val acc =  tensor(0.8440, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  23 / 40\n",
            "----------\n",
            "Train loss =  0.242168809368945  | Train acc =  tensor(0.9338, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6318739708513021  | Val acc =  tensor(0.8400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  24 / 40\n",
            "----------\n",
            "Train loss =  0.23208741858950135  | Train acc =  tensor(0.9371, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6295935939997435  | Val acc =  tensor(0.8540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  25 / 40\n",
            "----------\n",
            "Train loss =  0.21526713718317056  | Train acc =  tensor(0.9420, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6193155217915773  | Val acc =  tensor(0.8420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  26 / 40\n",
            "----------\n",
            "Train loss =  0.21253353904126682  | Train acc =  tensor(0.9404, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6325988043099642  | Val acc =  tensor(0.8460, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  27 / 40\n",
            "----------\n",
            "Train loss =  0.21271573764146767  | Train acc =  tensor(0.9431, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6188233010470867  | Val acc =  tensor(0.8400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  28 / 40\n",
            "----------\n",
            "Train loss =  0.2023749646039037  | Train acc =  tensor(0.9450, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6483614351600409  | Val acc =  tensor(0.8420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  29 / 40\n",
            "----------\n",
            "Train loss =  0.19538268684382326  | Train acc =  tensor(0.9483, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6442687520757318  | Val acc =  tensor(0.8420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  30 / 40\n",
            "----------\n",
            "Train loss =  0.19400078178062077  | Train acc =  tensor(0.9452, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6243570139631629  | Val acc =  tensor(0.8420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  31 / 40\n",
            "----------\n",
            "Train loss =  0.18668599567261704  | Train acc =  tensor(0.9501, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6271149143576622  | Val acc =  tensor(0.8500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  32 / 40\n",
            "----------\n",
            "Train loss =  0.18004470319645097  | Train acc =  tensor(0.9488, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6354882959276438  | Val acc =  tensor(0.8500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  33 / 40\n",
            "----------\n",
            "Train loss =  0.1805525441594117  | Train acc =  tensor(0.9505, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6486287284642458  | Val acc =  tensor(0.8460, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  34 / 40\n",
            "----------\n",
            "Train loss =  0.1728199505252622  | Train acc =  tensor(0.9536, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6269690534099936  | Val acc =  tensor(0.8460, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  35 / 40\n",
            "----------\n",
            "Train loss =  0.16479974092469055  | Train acc =  tensor(0.9569, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6279440391808748  | Val acc =  tensor(0.8500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  36 / 40\n",
            "----------\n",
            "Train loss =  0.16663531655151592  | Train acc =  tensor(0.9585, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6138043692335486  | Val acc =  tensor(0.8500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  37 / 40\n",
            "----------\n",
            "Train loss =  0.1598566710535023  | Train acc =  tensor(0.9596, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6189137818291783  | Val acc =  tensor(0.8500, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  38 / 40\n",
            "----------\n",
            "Train loss =  0.1614438943586677  | Train acc =  tensor(0.9538, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6058186683803797  | Val acc =  tensor(0.8540, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  39 / 40\n",
            "----------\n",
            "Train loss =  0.15013979891674561  | Train acc =  tensor(0.9606, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6482549365609884  | Val acc =  tensor(0.8480, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  40 / 40\n",
            "----------\n",
            "Train loss =  0.1507083168689009  | Train acc =  tensor(0.9584, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.6208293838426471  | Val acc =  tensor(0.8520, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-oQtmGwLWAU",
        "outputId": "7b18ae29-5fb6-4961-f7d6-9297c16bcca6"
      },
      "source": [
        "name = 'QC_V4Extended'\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV4, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV4, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV4.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  2.745063591421696  | Train acc =  tensor(0.4486, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.8576382100582123  | Val acc =  tensor(0.6740, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 10\n",
            "----------\n",
            "Train loss =  1.623408089255729  | Train acc =  tensor(0.7915, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.3350325599312782  | Val acc =  tensor(0.7900, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 10\n",
            "----------\n",
            "Train loss =  1.1152389934885572  | Train acc =  tensor(0.8863, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  1.0590244680643082  | Val acc =  tensor(0.8380, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 10\n",
            "----------\n",
            "Train loss =  0.8239957216190316  | Train acc =  tensor(0.9312, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.8576691783964634  | Val acc =  tensor(0.8820, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 10\n",
            "----------\n",
            "Train loss =  0.6073561061544028  | Train acc =  tensor(0.9595, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.7956339623779058  | Val acc =  tensor(0.8720, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 10\n",
            "----------\n",
            "Train loss =  0.45865206193854235  | Train acc =  tensor(0.9749, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5976640935987234  | Val acc =  tensor(0.9320, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 10\n",
            "----------\n",
            "Train loss =  0.3457694242746509  | Train acc =  tensor(0.9846, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.593293915502727  | Val acc =  tensor(0.9200, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 10\n",
            "----------\n",
            "Train loss =  0.26885156651512226  | Train acc =  tensor(0.9895, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5519245937466621  | Val acc =  tensor(0.9260, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 10\n",
            "----------\n",
            "Train loss =  0.22164024242706465  | Train acc =  tensor(0.9921, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5736413327977061  | Val acc =  tensor(0.9180, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 10\n",
            "----------\n",
            "Train loss =  0.17685069666619888  | Train acc =  tensor(0.9938, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.49021182395517826  | Val acc =  tensor(0.9320, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nMgMxVwPMdJ",
        "outputId": "0439f662-015d-43b6-9aa9-644b1907db74"
      },
      "source": [
        "name = 'QC_V4Extended'\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch ', epoch + 1, '/', EPOCHS)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  train_acc, train_loss = train_epoch(classifierV4, train_loader, crit, optim, device, len(train_data))\n",
        "  print('Train loss = ', train_loss, ' | Train acc = ', train_acc)\n",
        "  \n",
        "  val_acc, val_loss = eval(classifierV4, test_loader, crit, device, len(test_data))\n",
        "  print('Val loss = ', val_loss, ' | Val acc = ', val_acc)\n",
        "\n",
        "  if val_acc > best_acc:\n",
        "    best_acc = val_acc\n",
        "    torch.save(classifierV4.state_dict(), model_path + name + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 / 10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss =  0.14806187017793543  | Train acc =  tensor(0.9965, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5205845097079873  | Val acc =  tensor(0.9240, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  2 / 10\n",
            "----------\n",
            "Train loss =  0.1229721963057044  | Train acc =  tensor(0.9965, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.49584263237193227  | Val acc =  tensor(0.9300, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  3 / 10\n",
            "----------\n",
            "Train loss =  0.10516475352366068  | Train acc =  tensor(0.9978, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.45715733245015144  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  4 / 10\n",
            "----------\n",
            "Train loss =  0.08819445157260225  | Train acc =  tensor(0.9987, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.4412646237760782  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  5 / 10\n",
            "----------\n",
            "Train loss =  0.07862777927378464  | Train acc =  tensor(0.9987, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.4592279091011733  | Val acc =  tensor(0.9340, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  6 / 10\n",
            "----------\n",
            "Train loss =  0.0655032347517404  | Train acc =  tensor(0.9989, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.45895257126539946  | Val acc =  tensor(0.9360, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  7 / 10\n",
            "----------\n",
            "Train loss =  0.0556048742163251  | Train acc =  tensor(0.9993, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.47721588728018105  | Val acc =  tensor(0.9360, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  8 / 10\n",
            "----------\n",
            "Train loss =  0.04966921315729966  | Train acc =  tensor(0.9993, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5050810989923775  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  9 / 10\n",
            "----------\n",
            "Train loss =  0.04129037469603688  | Train acc =  tensor(0.9998, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.4929218189790845  | Val acc =  tensor(0.9420, device='cuda:0', dtype=torch.float64)\n",
            "Epoch  10 / 10\n",
            "----------\n",
            "Train loss =  0.036079016078416015  | Train acc =  tensor(0.9996, device='cuda:0', dtype=torch.float64)\n",
            "Val loss =  0.5083693170454353  | Val acc =  tensor(0.9400, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew0QGl7ISOpd",
        "outputId": "bc63e54f-0829-45a5-cc5b-efc3419a87f2"
      },
      "source": [
        "best_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9420, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}